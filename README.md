# Customer Orders ETL Pipeline ğŸ›’

This is a beginner-friendly data engineering project that demonstrates a basic ETL (Extract, Transform, Load) pipeline using Python and SQLite.

## ğŸ”§ Tools Used
- Python 3
- Pandas
- SQLite

## ğŸš€ Project Flow
1. **Extract** data from a CSV file
2. **Transform** it by cleaning and formatting
3. **Load** it into an SQLite database

## ğŸ—‚ï¸ Folder Structure
- `data/raw/` â€“ Original CSV file
- `data/processed/` â€“ Cleaned CSV output
- `scripts/` â€“ ETL logic
- `database/` â€“ SQLite DB file

## ğŸ“¦ How to Run
```bash
pip install -r requirements.txt
python main.py
```

## ğŸ“š Output
- `cleaned_orders.csv` in `data/processed/`
- SQLite database file: `orders.db`

## ğŸ’¡ Future Improvements
- Replace SQLite with PostgreSQL
- Schedule ETL with Apache Airflow
- Push data to AWS S3
